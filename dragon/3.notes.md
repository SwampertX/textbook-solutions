# Lexical Analysis

## Glossary

| Word    | Definition                                                                                                                         |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| token   | A terminal. For example, `if`, `else`, `number`, `literal`. In programs, usually represented by a pair of (token_name, attribute). |
| lexeme  | A "word" in the language sense. Belongs to a particular kind of token. Eg. 1, 2, "hello", if, else                                 |
| pattern | Matches characters to lexemes of a token.                                                                                          |

## 3.1 The Role of the Lexical Analyzer

Splitting the analysis phase of a compiler into _lexical analysis_ and _parsing_ can:

1. Separate concerns. _Lexical Analyzers_ like [Flex](https://github.com/westes/flex) remove comments and
   extra whitespaces. Then _Parsers_ take tokens as stream from _Lexical Analyzers_.
2. Make _Lexical Analyzers_ faster with special techniques on lexing programs and buffering input.
3. _Lexical Analyzers_ can deal with input-device-specific peculiarities. (I'm guessing end-of-line etc)

The following tokens cover most constructs seen in programming languages:

1. One token for each keyword, such as `if`, `else`, `while` etc.
2. Tokens for the operators. Comparison (`>=`, `==`), arithmetic (`+`, `%`, `>>`)
3. One token for all identifiers. (ie all variable names)
4. One or more token for constants (numbers, string literals...)
5. Tokens for each puncuation symbol. `{`, `}`, `,`, etc

What happens when there is a typo?

Possibilities:

1. Register as an identifier. (since it is the most permissive, and Lexers do not check for validity)
2. Delete character from input stream until valid pattern is found.
3. Preprocess by editing the least edit distance to make the program matchable. (Too expensive)

